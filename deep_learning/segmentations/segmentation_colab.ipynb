{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DneN_uDmG5F8",
        "outputId": "84e5a571-e531-4d25-9c15-89a8206c878e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.2.52\n",
            "Uninstalling opencv-python-headless-4.5.2.52:\n",
            "  Successfully uninstalled opencv-python-headless-4.5.2.52\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Using cached opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.19.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.4.12)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.6.3)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.62.3)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.5.2.52)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (3.10.0.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.2.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Requirement already satisfied: cv2-tools in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: python-constraint in /usr/local/lib/python3.7/dist-packages (from cv2-tools) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cv2-tools) (1.19.5)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.7/dist-packages (from cv2-tools) (4.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imagehash->cv2-tools) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imagehash->cv2-tools) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->cv2-tools) (1.2.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imagehash->cv2-tools) (7.1.2)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.5.9-py3-none-any.whl (527 kB)\n",
            "\u001b[K     |████████████████████████████████| 527 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 55.9 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.0-py3-none-any.whl (396 kB)\n",
            "\u001b[K     |████████████████████████████████| 396 kB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.10)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 56.1 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 59.9 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=9b79db715f9061078bfb05172da6c1384ab7de67aeadf8a26343d770e584fd0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: setuptools, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, future, pytorch-lightning\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.1.0 future-0.18.2 multidict-6.0.2 pyDeprecate-0.3.1 pytorch-lightning-1.5.9 setuptools-59.5.0 torchmetrics-0.7.0 yarl-1.7.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62 -y\n",
        "!pip install opencv-python-headless==4.5.2.52\n",
        "!pip install segmentation-models-pytorch\n",
        "!pip install -U albumentations\n",
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python\n",
        "!pip install cv2-tools\n",
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVJQq57x74gH",
        "outputId": "93dcdaa0-3099-45ab-c6c4-7b0f1b0ee139"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('1.5.9', '0.2.1')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "# import torchvision.transforms as T\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import callbacks\n",
        "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "from pytorch_lightning.utilities.seed import seed_everything\n",
        "import segmentation_models_pytorch as smp\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "MASK_FG = 1\n",
        "MASK_BG = 2\n",
        "MASK_IGNORE = 3\n",
        "\n",
        "pl.__version__, smp.__version__#, python.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yNaOOsJO74XX"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"model\": {\n",
        "        \"arch\": \"Unet\",\n",
        "        \"encoder_name\": \"inceptionv4\", #resnet50\n",
        "        \"encoder_weights\": \"imagenet\",\n",
        "        \"in_channels\": 3,\n",
        "        \"classes\": 1,\n",
        "    },\n",
        "    \"train\": {\n",
        "        \"epoch\": 10,\n",
        "    },\n",
        "    \"optim\": {\n",
        "        \"weight_decay\": 0.001,\n",
        "        \"lr_max\": 2e-3,\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqnwU7rT74T4",
        "outputId": "52b6f95f-cc5a-48f5-95ed-4f1718910afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "head: cannot open '../input/the-oxfordiiit-pet-dataset/annotations/annotations/list.txt' for reading: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 ../input/the-oxfordiiit-pet-dataset/annotations/annotations/list.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj0I_EdZ74PN"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    \"../input/the-oxfordiiit-pet-dataset/annotations/annotations/list.txt\",\n",
        "    delimiter=\" \",\n",
        "    skiprows=6,\n",
        "    header=None,\n",
        "    names=[\"stem\", \"class_id\", \"species\", \"breed\"]\n",
        ")\n",
        "df[\"class_name\"] = df.stem.map(lambda x: x.split(\"_\")[0])\n",
        "df[\"image\"] = df.stem.map(lambda x: f\"../input/the-oxfordiiit-pet-dataset/images/images/{x}.jpg\")\n",
        "df[\"trimap\"] = df.stem.map(lambda x: f\"../input/the-oxfordiiit-pet-dataset/annotations/annotations/trimaps/{x}.png\")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-6DOGKj74LP"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1)\n",
        "sns.histplot(df.class_id)\n",
        "plt.subplot(1,3,2)\n",
        "sns.histplot(df.species, discrete=True)\n",
        "plt.subplot(1,3,3)\n",
        "sns.histplot(df.breed)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR_cHAPn74Id"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[0])\n",
        "img = Image.open(df.image[0])\n",
        "annot = Image.open(df.trimap[0])\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(annot)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LbMjKks74F1"
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "if False:\n",
        "    for img, annot in tqdm(zip(df.image, df.trimap), total=len(df)):\n",
        "        Image.open(img).verify()\n",
        "        Image.open(annot).verify()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batXMKKE73zZ"
      },
      "outputs": [],
      "source": [
        "class IIITDataset(Dataset):\n",
        "    def __init__(self, df, tfm=None):\n",
        "        self.df = df\n",
        "        self.tfm = tfm\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.df.image.iloc[i]).convert('RGB')\n",
        "        mask = Image.open(self.df.trimap.iloc[i])\n",
        "        img = np.asarray(img)\n",
        "        mask = np.asarray(mask)\n",
        "        if self.tfm:\n",
        "            augmented = self.tfm(image=img, mask=mask)\n",
        "            img, mask = augmented[\"image\"], augmented[\"mask\"]\n",
        "        return img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKBSMon973wY"
      },
      "outputs": [],
      "source": [
        "train_tfm = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5),\n",
        "    A.RandomScale(),\n",
        "    A.Rotate(border_mode=cv2.BORDER_CONSTANT, mask_value=MASK_BG),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.SmallestMaxSize(224), A.RandomCrop(224, 224),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "val_tfm = A.Compose([\n",
        "    A.SmallestMaxSize(224), A.CenterCrop(224, 224),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "def imagenet_denorm(x):\n",
        "    \"\"\"x: array-like with shape (..., H, W, C)\"\"\"\n",
        "    return x * imagenet_std + imagenet_mean\n",
        "\n",
        "skf = StratifiedKFold(5)\n",
        "train_idx, val_idx = next(iter(skf.split(df, df.class_id)))\n",
        "train_df = df.iloc[train_idx]\n",
        "val_df = df.iloc[val_idx]\n",
        "\n",
        "train_ds = IIITDataset(train_df, tfm=train_tfm)\n",
        "val_ds = IIITDataset(val_df, tfm=val_tfm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVxuyrCq73sz"
      },
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, mask = train_ds[0]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(imagenet_denorm(img.numpy().transpose(1,2,0)))\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask == MASK_FG)\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf9eRmks73pQ"
      },
      "outputs": [],
      "source": [
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Bwp9MDa73mG"
      },
      "outputs": [],
      "source": [
        "class Task(LightningModule):\n",
        "    def __init__(self, cfg, train_df, val_df):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "    def setup(self, stage=None):\n",
        "        global train_tfm\n",
        "        global val_tfm\n",
        "        self.model = smp.create_model(**self.cfg[\"model\"])\n",
        "        self.train_ds = IIITDataset(self.train_df, tfm=train_tfm)\n",
        "        self.val_ds = IIITDataset(self.val_df, tfm=val_tfm)\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss(reduction='none')\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=16,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_ds,\n",
        "            batch_size=16,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        fg = (t.detach() == MASK_FG).float()\n",
        "        valid_mask = (t.detach() != MASK_IGNORE)\n",
        "        y = self.model(x).squeeze()\n",
        "        loss = torch.masked_select(self.loss_fn(y, fg), valid_mask).mean()\n",
        "        return loss\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        fg = (t.detach() == MASK_FG).float()\n",
        "        valid_mask = (t.detach() != MASK_IGNORE)\n",
        "        y = self.model(x).squeeze()\n",
        "        loss = torch.masked_select(self.loss_fn(y, fg), valid_mask).mean()\n",
        "        return {\"loss\": loss}\n",
        "    def training_epoch_end(self, outputs):\n",
        "        self.log(\"loss\", np.mean([x[\"loss\"].detach().cpu().numpy() for x in outputs]))\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.log(\"val_loss\", np.mean([x[\"loss\"].detach().cpu().numpy() for x in outputs]))\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), weight_decay=self.cfg[\"optim\"][\"weight_decay\"])\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
        "                    optimizer, self.cfg[\"optim\"][\"lr_max\"],\n",
        "                    epochs=self.cfg[\"train\"][\"epoch\"],\n",
        "                    steps_per_epoch=len(self.train_dataloader())\n",
        "                ),\n",
        "                \"interval\": \"step\",\n",
        "            },\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywXQv-8Y73jN"
      },
      "outputs": [],
      "source": [
        "class PredictImageCallback(callbacks.Callback):\n",
        "    def __init__(self, model: LightningModule):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "#     def on_train_start(self, trainer, pl_module):\n",
        "#         # visualize one batch from val #\n",
        "#         xs, ts = next(iter(self.model.val_dataloader()))\n",
        "        \n",
        "#         arr = xs.numpy()\n",
        "#         arr = (imagenet_denorm(arr.transpose(0,2,3,1)) * 255).astype(np.uint8)\n",
        "#         self.model.experiment.add_image(\"val-image\", arr, dataformats='NHWC')\n",
        "#         self.model.experiment.add_image(\"val-mask\", np.where(ts[:,:,:,None] == MASK_FG, arr, 0), dataformats='NHWC')\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        # visualize one batch from predicted val #\n",
        "        xs, ts = next(iter(self.model.val_dataloader()))\n",
        "        with torch.no_grad():\n",
        "            ys = self.model(xs.to(self.model.device)).cpu().numpy().squeeze()\n",
        "        arr = xs.numpy()\n",
        "        arr = (imagenet_denorm(arr.transpose(0,2,3,1)) * 255).astype(np.uint8)\n",
        "        self.model.logger.experiment.add_image(\"val-image\", arr, dataformats='NHWC')\n",
        "        self.model.logger.experiment.add_image(\"val-mask\", np.where(ts[:,:,:,None] == MASK_FG, arr, 0), dataformats='NHWC')\n",
        "        self.model.logger.experiment.add_image(\"val-pred\", np.where(ys[:,:,:,None] > 0, arr, 0), dataformats='NHWC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrZJMlaH73gQ"
      },
      "outputs": [],
      "source": [
        "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df.class_id)):\n",
        "    train_df = df.loc[train_idx].reset_index(drop=True)\n",
        "    val_df = df.loc[val_idx].reset_index(drop=True)\n",
        "    task = Task(config, train_df, val_df)\n",
        "    earystopping = EarlyStopping(monitor=\"val_loss\")\n",
        "    lr_monitor = callbacks.LearningRateMonitor(logging_interval='step')\n",
        "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
        "        filename=\"best_loss\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_top_k=1,\n",
        "        mode=\"min\",\n",
        "        save_last=False,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "    logger = TensorBoardLogger(f\"fold-{fold}\")\n",
        "    \n",
        "    trainer = pl.Trainer(\n",
        "        gpus=1,\n",
        "        logger=logger,\n",
        "        max_epochs=config[\"train\"][\"epoch\"],\n",
        "        callbacks=[lr_monitor, loss_checkpoint, earystopping, PredictImageCallback(task)],\n",
        "    )\n",
        "    trainer.fit(task)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihxVDLR873dQ"
      },
      "outputs": [],
      "source": [
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "from glob import glob\n",
        "from io import BytesIO\n",
        "from matplotlib import gridspec\n",
        "\n",
        "def show_log(fold):\n",
        "    path = glob(f'./fold-{fold}/default/version_0/events*')[0]\n",
        "    event_acc = EventAccumulator(path, size_guidance={'scalars': 0})\n",
        "    event_acc.Reload()\n",
        "\n",
        "    scalars = {}\n",
        "    for tag in event_acc.Tags()['scalars']:\n",
        "        events = event_acc.Scalars(tag)\n",
        "        scalars[tag] = [event.value for event in events]\n",
        "\n",
        "    images = {}\n",
        "    for tag in event_acc.Tags()['images']:\n",
        "        events = event_acc.Images(tag)\n",
        "        images[tag] = [Image.open(BytesIO(event.encoded_image_string)) for event in events]\n",
        "    \n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(len(scalars['lr-AdamW'])), scalars['lr-AdamW'])\n",
        "    plt.xlabel('steps')\n",
        "    plt.ylabel('lr')\n",
        "    plt.title('adamw lr')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(len(scalars['loss'])), scalars['loss'], label='train_loss')\n",
        "    plt.plot(range(len(scalars['val_loss'])), scalars['val_loss'], label='val_loss')\n",
        "    plt.legend()\n",
        "    plt.ylabel('bce')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.title('train/val loss')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(16, 10))\n",
        "    gs = gridspec.GridSpec(5,2)\n",
        "    ax = plt.subplot(gs[0,:])\n",
        "    ax.imshow(images[\"val-image\"][0])\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    for i in range(4):\n",
        "        ax0 = plt.subplot(gs[i+1,0])\n",
        "        ax1 = plt.subplot(gs[i+1,1])\n",
        "        ax0.set_title(f\"epoch {i+1}:pred\")\n",
        "        ax0.imshow(images[\"val-pred\"][i])\n",
        "        ax0.set_xticks([]); ax0.set_yticks([])\n",
        "        ax1.set_title(f\"epoch {i+1}:gt\")\n",
        "        ax1.imshow(images[\"val-mask\"][i])\n",
        "        ax1.set_xticks([]); ax1.set_yticks([])\n",
        "            \n",
        "    plt.show()\n",
        "\n",
        "for i in range(5):\n",
        "    show_log(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwrz8jYG73Nz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
