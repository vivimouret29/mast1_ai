{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed427289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc905c",
   "metadata": {},
   "source": [
    "L'objectif de ce TP est de créer un modèle NN simple (MLP), qui utilise des couches \"fully connected\", pour faire la classification de chiffres manuscrites du dataset MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebd59b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0b097",
   "metadata": {},
   "source": [
    "Importer et préparer le dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e8bea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the training dataset.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# reshape the data by flattening the images\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "x_test = np.reshape(x_test, (-1, 784))\n",
    "\n",
    "# Reserve 10,000 samples from the training data for validation.\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4a131",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd235f",
   "metadata": {},
   "source": [
    "Nous voulons construire un modèle MLP (multi layer perceptron).\n",
    "Pour cela, nous avons besoin d'abord de définir les couches de perceptrons qui vont composer le modèle, c'est à dire de couches \"fully connected\" qui prendent en entrée un vecteur de valeurs $x$ et qui donnent en sortie une activation $a = f(W*x + b)$, où:\n",
    "\n",
    "* $W$ est la matrice des poids\n",
    "* $b$ est le vecteur de biais\n",
    "* $f(.)$ est la fonction d'activation\n",
    "\n",
    "Nous allons créer une classe \"FCLayer\" pour des objets de type \"fully connected layer\".\n",
    "La création se fait par \"subclassing\" de la classe générique \"tf.keras.layers.Layer\" utilisée pour créer des couches customisées dans Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf250ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une classe FCLayer pour des objets de type \"fully connected layer\"\n",
    "\n",
    "class FCLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    # fonction pour initiliser un objet de la classe\n",
    "    def __init__(self, units=32, input_dim=32, use_relu=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        \n",
    "        # définition de la variable de la classe\n",
    "        self.use_relu = use_relu\n",
    "        \n",
    "        # definition des poids W\n",
    "        w_init = tf.random_normal_initializer()  # initialisation aléatoire normale\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "        # definition du biais b\n",
    "        b_init = tf.zeros_initializer()  # initialisation à zéro\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "    # pour calculer la sortie du layer\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # calcul des sorties\n",
    "        layer = tf.matmul(inputs, self.w) + self.b\n",
    "        \n",
    "        # utiliser activation si c'est le cas\n",
    "        if self.use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03147e7d",
   "metadata": {},
   "source": [
    "Maintenant que nous avons à disposition les briques pour construire notre modèle, nous pouvons voir comment faire cela dans Keras.\n",
    "Nous allons construire un modèle qui prend en entrée les images aplaties (flatten), c'est à dire des vecteurs de taille 784, ensuite il est composé de deux couches \"fully connected\", chacune de 32 neurones avec activation ReLU, et une couche finale de classification composée par un nombre de neurones égal au nombre de classes, et sans activation, pour pouvoir donner en sortie la valeur de logit pour chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50eaa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 16:31:34.548179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-13 16:31:34.548301: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-13 16:31:34.548365: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-DMWORK): /proc/driver/nvidia/version does not exist\n",
      "2021-11-13 16:31:34.549273: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# create a NN model with the FCLayer\n",
    "input_shape = 784\n",
    "\n",
    "inputs = keras.Input(shape=(input_shape,), name=\"digits\")\n",
    "x1 = FCLayer(units=32, input_dim=input_shape, use_relu=True)(inputs)\n",
    "x2 = FCLayer(units=32, input_dim=32, use_relu=True)(x1)\n",
    "outputs = FCLayer(units=10, input_dim=32, use_relu=False)(x2)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f7146",
   "metadata": {},
   "source": [
    "# Entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda95279",
   "metadata": {},
   "source": [
    "Entraînons le modèle en utilisant une méthode déscente de gradients stochastique (avec moni-batches) avec une boucle d'entraînement personnalisée.\n",
    "\n",
    "Tout d'abord, nous aurons besoin d'un optimiseur et d'une loss function. Nous choisissons un optimiseur SGD et une loss Categorical cross entropy, comme il s'agit d'un problème de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6069eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd74388",
   "metadata": {},
   "source": [
    "En ce qui concerne les métriques d'évaluation du modèle, comme il s'agit d'un problème de classification nous utilison une métrique \"categorical cross-entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "834d8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the metrics.\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53953668",
   "metadata": {},
   "source": [
    "Préparation du dataset : division en mini-batches pour pouvoir appliquer un algorithme de déscente de gradient stochastique. Pour cela, nous utilisons la fonction tf.data.Dataset.from_tensor_slices, une fonction TF2 qui gère automatiquement les données et leur division en minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535cd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 16:31:35.880770: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39200000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11ee53",
   "metadata": {},
   "source": [
    "Voici notre boucle d'entraînement :\n",
    "\n",
    "* Nous ouvrons une boucle qui parcourt les épochs\n",
    "* Pour chaque époque, nous ouvrons une boucle qui itère sur l'ensemble de données, en mini-batches\n",
    "* Pour chaque mini-batch, nous ouvrons un GradientTape(), une fonctionnalité de tensorflow 2.X pour pouvoir faire la backpropagation et le calcul des gradients.\n",
    "* A l'intérieur du GradientTape, nous appelons le modèle (forward pass) et calculons la loss function\n",
    "* En dehors du GradientTape, on récupère les gradients des poids du modèle par rapport à la loss\n",
    "* Enfin, nous utilisons l'optimiseur pour mettre à jour les poids du modèle en fonction des gradients\n",
    "* Ensuite, pour chaque epoch nous allons calculer et visualiser des métriques pour monitorer l'état d'anacement de l'entrainement et la qualité du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a357ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 16:31:39.498628: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39200000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 0: 6.4795\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 1.0686\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.8814\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.3087\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.7339\n",
      "Validation acc: 0.8445\n",
      "Time taken: 20.31s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.3739\n",
      "Seen so far: 64 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 16:31:59.808510: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39200000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 200: 0.4945\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.5349\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.3663\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.8664\n",
      "Validation acc: 0.8786\n",
      "Time taken: 16.87s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.5524\n",
      "Seen so far: 64 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 16:32:16.684864: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39200000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 200: 0.4085\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.2477\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.2795\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.8930\n",
      "Validation acc: 0.9033\n",
      "Time taken: 19.56s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.3155\n",
      "Seen so far: 64 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 16:32:36.236535: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39200000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 200: 0.3672\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1930\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.2005\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9060\n",
      "Validation acc: 0.9092\n",
      "Time taken: 28.34s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.7392\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.3624\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.2799\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.2028\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9163\n",
      "Validation acc: 0.9250\n",
      "Time taken: 39.05s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.1357\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.2995\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1909\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.2732\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9224\n",
      "Validation acc: 0.9225\n",
      "Time taken: 21.71s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.2269\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.2815\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.4341\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.1417\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9277\n",
      "Validation acc: 0.9282\n",
      "Time taken: 18.16s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.3930\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.2528\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.3892\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.1473\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9326\n",
      "Validation acc: 0.9286\n",
      "Time taken: 21.77s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.4419\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.4985\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1602\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.1640\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9356\n",
      "Validation acc: 0.9257\n",
      "Time taken: 13.94s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.3568\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.1460\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.2056\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.3579\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9384\n",
      "Validation acc: 0.9355\n",
      "Time taken: 14.44s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 0.1506\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.3083\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1985\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.1731\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9410\n",
      "Validation acc: 0.9411\n",
      "Time taken: 14.54s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 0.2131\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.1238\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.2735\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.2877\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9437\n",
      "Validation acc: 0.9396\n",
      "Time taken: 13.51s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 0.1470\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0434\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1192\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.1345\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9462\n",
      "Validation acc: 0.9362\n",
      "Time taken: 12.59s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 0.3434\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0720\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.2189\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.2881\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9477\n",
      "Validation acc: 0.9344\n",
      "Time taken: 14.25s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 0.2008\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.2525\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1661\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0930\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9495\n",
      "Validation acc: 0.9461\n",
      "Time taken: 19.72s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 0.1250\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.1210\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.4381\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0813\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9512\n",
      "Validation acc: 0.9487\n",
      "Time taken: 28.21s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 0.0622\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.1288\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1750\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.3095\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9521\n",
      "Validation acc: 0.9409\n",
      "Time taken: 22.14s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 0.1009\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.2008\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1258\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0871\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9540\n",
      "Validation acc: 0.9491\n",
      "Time taken: 18.38s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 0.2701\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.2266\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1503\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.3967\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9557\n",
      "Validation acc: 0.9490\n",
      "Time taken: 15.50s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 0.1175\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0905\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.2114\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0560\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.9565\n",
      "Validation acc: 0.9495\n",
      "Time taken: 14.50s\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f6b529",
   "metadata": {},
   "source": [
    "## Biblio\n",
    "\n",
    "* https://www.tensorflow.org/guide/keras/custom_layers_and_models\n",
    "\n",
    "* https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12817300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
